{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1KXenqWIBkyNhfLxk37Tm-g2NQ9K9egzy",
      "authorship_tag": "ABX9TyMgC93cOnMmQe9GikTvbNe8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janaghoniem/Housing-Prices-Prediction-using-Machine-Learning/blob/main/Feature_Selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Kn9eO7GJS9OU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Machine Learning/cleaned_dataset.csv')\n",
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2Wj43jTYaOk",
        "outputId": "aa071aa2-d9e1-44c7-d20e-c91a05c2fbd1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1460 entries, 0 to 1459\n",
            "Data columns (total 75 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   MSSubClass     1460 non-null   int64  \n",
            " 1   MSZoning       1460 non-null   object \n",
            " 2   LotFrontage    1460 non-null   float64\n",
            " 3   LotArea        1460 non-null   float64\n",
            " 4   Street         1460 non-null   object \n",
            " 5   LotShape       1460 non-null   object \n",
            " 6   LandContour    1460 non-null   object \n",
            " 7   Utilities      1460 non-null   object \n",
            " 8   LotConfig      1460 non-null   object \n",
            " 9   LandSlope      1460 non-null   object \n",
            " 10  Neighborhood   1460 non-null   object \n",
            " 11  Condition1     1460 non-null   object \n",
            " 12  Condition2     1460 non-null   object \n",
            " 13  BldgType       1460 non-null   object \n",
            " 14  HouseStyle     1460 non-null   object \n",
            " 15  OverallQual    1460 non-null   int64  \n",
            " 16  OverallCond    1460 non-null   int64  \n",
            " 17  YearBuilt      1460 non-null   int64  \n",
            " 18  YearRemodAdd   1460 non-null   int64  \n",
            " 19  RoofStyle      1460 non-null   object \n",
            " 20  RoofMatl       1460 non-null   object \n",
            " 21  Exterior1st    1460 non-null   object \n",
            " 22  Exterior2nd    1460 non-null   object \n",
            " 23  MasVnrArea     1460 non-null   float64\n",
            " 24  ExterQual      1460 non-null   object \n",
            " 25  ExterCond      1460 non-null   object \n",
            " 26  Foundation     1460 non-null   object \n",
            " 27  BsmtQual       1423 non-null   object \n",
            " 28  BsmtCond       1423 non-null   object \n",
            " 29  BsmtExposure   1423 non-null   object \n",
            " 30  BsmtFinType1   1423 non-null   object \n",
            " 31  BsmtFinSF1     1460 non-null   float64\n",
            " 32  BsmtFinType2   1423 non-null   object \n",
            " 33  BsmtFinSF2     1460 non-null   int64  \n",
            " 34  BsmtUnfSF      1460 non-null   float64\n",
            " 35  TotalBsmtSF    1460 non-null   int64  \n",
            " 36  Heating        1460 non-null   object \n",
            " 37  HeatingQC      1460 non-null   object \n",
            " 38  CentralAir     1460 non-null   object \n",
            " 39  Electrical     1460 non-null   object \n",
            " 40  1stFlrSF       1460 non-null   int64  \n",
            " 41  2ndFlrSF       1460 non-null   int64  \n",
            " 42  LowQualFinSF   1460 non-null   int64  \n",
            " 43  GrLivArea      1460 non-null   float64\n",
            " 44  BsmtFullBath   1460 non-null   int64  \n",
            " 45  BsmtHalfBath   1460 non-null   int64  \n",
            " 46  FullBath       1460 non-null   int64  \n",
            " 47  HalfBath       1460 non-null   int64  \n",
            " 48  BedroomAbvGr   1460 non-null   int64  \n",
            " 49  KitchenAbvGr   1460 non-null   int64  \n",
            " 50  KitchenQual    1460 non-null   object \n",
            " 51  TotRmsAbvGrd   1460 non-null   int64  \n",
            " 52  Functional     1460 non-null   object \n",
            " 53  Fireplaces     1460 non-null   float64\n",
            " 54  FireplaceQu    770 non-null    object \n",
            " 55  GarageType     1379 non-null   object \n",
            " 56  GarageYrBlt    1460 non-null   int64  \n",
            " 57  GarageFinish   1379 non-null   object \n",
            " 58  GarageCars     1460 non-null   float64\n",
            " 59  GarageArea     1460 non-null   float64\n",
            " 60  GarageQual     1379 non-null   object \n",
            " 61  GarageCond     1379 non-null   object \n",
            " 62  PavedDrive     1460 non-null   object \n",
            " 63  WoodDeckSF     1460 non-null   int64  \n",
            " 64  OpenPorchSF    1460 non-null   int64  \n",
            " 65  EnclosedPorch  1460 non-null   int64  \n",
            " 66  3SsnPorch      1460 non-null   int64  \n",
            " 67  ScreenPorch    1460 non-null   int64  \n",
            " 68  PoolArea       1460 non-null   int64  \n",
            " 69  MiscVal        1460 non-null   int64  \n",
            " 70  MoSold         1460 non-null   int64  \n",
            " 71  YrSold         1460 non-null   int64  \n",
            " 72  SaleType       1460 non-null   object \n",
            " 73  SaleCondition  1460 non-null   object \n",
            " 74  SalePrice      1460 non-null   float64\n",
            "dtypes: float64(10), int64(27), object(38)\n",
            "memory usage: 855.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Selection"
      ],
      "metadata": {
        "id": "js0uYuVDZDMg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. PCA/LDA + Recursive Feature Elimination\n",
        "PCA is used to reduce the dimensionality of the dataset while retaining most of the variance in the data.\n",
        "Recursive Feature Elimination (RFE) to select the most important features. (wrapper method)"
      ],
      "metadata": {
        "id": "Fgna-JKIZHf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/Machine Learning/scaled_dataset.csv')\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop('SalePrice', axis=1)  # Features (all columns except 'SalePrice')\n",
        "y = data['SalePrice']  # Target variable\n",
        "\n",
        "# Step 1: Apply PCA\n",
        "pca = PCA(n_components=0.95)  # Retain 95% of the variance\n",
        "X_pca = pca.fit_transform(X)  # Apply PCA to the already scaled data\n",
        "\n",
        "print(f\"Original number of features: {X.shape[1]}\")\n",
        "print(f\"Reduced number of features after PCA: {X_pca.shape[1]}\")\n",
        "\n",
        "# Step 2: Apply Recursive Feature Elimination (RFE)\n",
        "model = LinearRegression()  # Initialize Linear Regression model\n",
        "rfe = RFE(estimator=model, n_features_to_select=5)  # Select top 5 features\n",
        "X_rfe = rfe.fit_transform(X_pca, y)  # Fit RFE and transform the PCA-transformed data\n",
        "\n",
        "# Get the selected features\n",
        "selected_features = rfe.support_  # Boolean mask of selected features\n",
        "print(f\"Selected features mask: {selected_features}\")\n",
        "\n",
        "# Step 3: Train and evaluate the model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_rfe, y, test_size=0.2, random_state=42)\n",
        "model.fit(X_train, y_train)  # Train the Linear Regression model\n",
        "y_pred = model.predict(X_test)  # Make predictions\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error: {mse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKOBTDzQvVKF",
        "outputId": "a92c0467-2a82-49ec-b6f3-26087cf0cffa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original number of features: 168\n",
            "Reduced number of features after PCA: 16\n",
            "Selected features mask: [False  True False False False  True False  True False False  True False\n",
            " False  True False False]\n",
            "Mean Squared Error: 0.17922204116117624\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check unique categories in each categorical column\n",
        "for col in categorical_cols:\n",
        "    print(f\"{col}: {X[col].nunique()} unique categories\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "rTwAX_6maugE",
        "outputId": "aecb25a0-d0a2-474d-fd0c-397abf1696da"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'categorical_cols' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-1911a83c79d7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check unique categories in each categorical column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcategorical_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{col}: {X[col].nunique()} unique categories\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'categorical_cols' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. RFE with bayesian ridge"
      ],
      "metadata": {
        "id": "8PwT14tGcdxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/Machine Learning/scaled_dataset.csv')\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop('SalePrice', axis=1)  # Features (all columns except 'SalePrice')\n",
        "y = data['SalePrice']  # Target variable\n",
        "\n",
        "# Step 1: Apply Recursive Feature Elimination (RFE) with Bayesian Ridge\n",
        "model = BayesianRidge()  # Initialize Bayesian Ridge model\n",
        "rfe = RFE(estimator=model, n_features_to_select=5)  # Select top 5 features\n",
        "X_rfe = rfe.fit_transform(X, y)  # Fit RFE and transform the data\n",
        "\n",
        "# Get the selected features\n",
        "selected_features = X.columns[rfe.support_]  # Get the names of the selected features\n",
        "print(\"Selected features:\", selected_features)\n",
        "\n",
        "# Step 2: Train and evaluate the model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_rfe, y, test_size=0.2, random_state=42)\n",
        "model.fit(X_train, y_train)  # Train the Bayesian Ridge model\n",
        "y_pred = model.predict(X_test)  # Make predictions\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error: {mse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWpO1qdSu9GR",
        "outputId": "c0ec23e5-5fab-429d-ae2f-adb3bd4f5926"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected features: Index(['Condition2_PosN', 'RoofMatl_CompShg', 'RoofMatl_Roll',\n",
            "       'RoofMatl_WdShake', 'RoofMatl_WdShngl'],\n",
            "      dtype='object')\n",
            "Mean Squared Error: 0.7315471857821483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/Machine Learning/cleaned_dataset.csv')\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop('SalePrice', axis=1)  # Features (all columns except 'SalePrice')\n",
        "y = data['SalePrice']  # Target variable\n",
        "\n",
        "# Identify categorical and numeric columns\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Create a ColumnTransformer to preprocess the data\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numeric_cols),  # Standardize numeric columns\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols)  # One-hot encode categorical columns\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Step 1: Preprocess the data (standardize numeric and encode categorical)\n",
        "X_preprocessed = preprocessor.fit_transform(X)\n",
        "\n",
        "# Get feature names after preprocessing\n",
        "numeric_feature_names = numeric_cols.tolist()\n",
        "categorical_feature_names = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_cols)\n",
        "all_feature_names = numeric_feature_names + categorical_feature_names.tolist()\n",
        "\n",
        "# Step 2: Initialize Bayesian Ridge model\n",
        "model = BayesianRidge()\n",
        "\n",
        "# Step 3: Apply Recursive Feature Elimination (RFE)\n",
        "rfe = RFE(estimator=model, n_features_to_select=5)  # Select top 5 features\n",
        "X_rfe = rfe.fit_transform(X_preprocessed, y)\n",
        "\n",
        "# Get the selected features\n",
        "selected_features = rfe.support_\n",
        "selected_feature_names = [all_feature_names[i] for i in range(len(all_feature_names)) if selected_features[i]]\n",
        "\n",
        "print(\"Selected features:\", selected_feature_names)\n",
        "print(\"Feature ranking:\", rfe.ranking_)\n",
        "\n",
        "# Step 4: Train and evaluate the model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_rfe, y, test_size=0.2, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error: {mse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hn-SINlckYZ",
        "outputId": "acd5a5ea-0161-4592-a2c4-07832d85240f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected features: ['MSZoning_C (all)', 'Neighborhood_NoRidge', 'Exterior1st_BrkComm', 'KitchenQual_Ex', 'Functional_Maj2']\n",
            "Feature ranking: [202 242  37  25  50  21 125 272 249 277  77  44  71 234 225   9 170 268\n",
            " 173 179 246 141 146 138 273  61 157 189 232 276 275 274 235 260 254 222\n",
            "   1  42  59  60  98  64  91 215 130  68 209  85 134  86 135  57  83 147\n",
            " 109  65  62 216 230  81  36 266 186 188  35 199 156  17  54 154 111   2\n",
            "  79  87 150  84   1   5  90 224  88 262  75   4 155 194 100 184  58  95\n",
            "  63  33 160 196  55 253  27  28  12   8 178 192  22 248 201  10 110 200\n",
            " 103  51  70  94 211 101  34  69 265 180  92 181  72  24   6 206  13  16\n",
            " 226 140 113  14 172 219   1  45 102 208 116  76 151 236 149 258  97 107\n",
            " 175 238 163 142 182  66 176 240 106 251 195 270 204 210  96 108 239 247\n",
            " 237 221 220  52  89 148 187 231 112 191 161 256  20  23  47 267 123 122\n",
            " 212 120 245  48 244 190 217  11 205 131 183 115 213 114 133 159 158 218\n",
            " 136  80 185 264 119 198 197 174 139  18  15  99  30  67 228 255 241 193\n",
            "   3  93 250 117 171 162 165   1 129 128 127  82   1  31  32 118   7  29\n",
            " 227 152 229 263 257 164  53 167 168 233 177 166 252 214 269 261 243  19\n",
            " 121  26  46 126 259 169  56 144 143 145 124 223 207 132  39 153 203  73\n",
            "  38 137  74  78  40 105  49  43 104  41 271]\n",
            "Mean Squared Error: 0.12919454525282403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Recursive Feature Elimination with Cross-Validation (RFECV)"
      ],
      "metadata": {
        "id": "-dCKie7CdOj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/Machine Learning/cleaned_dataset.csv')\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop('SalePrice', axis=1)  # Features (all columns except 'SalePrice')\n",
        "y = data['SalePrice']  # Target variable\n",
        "\n",
        "# Identify categorical and numeric columns\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Create a ColumnTransformer to preprocess the data\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numeric_cols),  # Standardize numeric columns\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols)  # One-hot encode categorical columns\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Step 1: Preprocess the data (standardize numeric and encode categorical)\n",
        "X_preprocessed = preprocessor.fit_transform(X)\n",
        "\n",
        "# Get feature names after preprocessing\n",
        "numeric_feature_names = numeric_cols.tolist()\n",
        "categorical_feature_names = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_cols)\n",
        "all_feature_names = numeric_feature_names + categorical_feature_names.tolist()\n",
        "\n",
        "# Convert preprocessed data back to a DataFrame (for easier handling)\n",
        "X_preprocessed_df = pd.DataFrame(X_preprocessed, columns=all_feature_names)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed_df, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the model\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Apply RFECV\n",
        "selector = RFECV(model, step=1, cv=5)  # Use 5-fold cross-validation\n",
        "selector = selector.fit(X_train, y_train)\n",
        "\n",
        "# Get the selected features\n",
        "selected_features = X_train.columns[selector.support_]\n",
        "print(\"Selected features (RFECV):\", selected_features)\n",
        "\n",
        "# Train and evaluate the model\n",
        "X_train_selected = selector.transform(X_train)\n",
        "X_test_selected = selector.transform(X_test)\n",
        "\n",
        "model.fit(X_train_selected, y_train)\n",
        "y_pred = model.predict(X_test_selected)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error (RFECV): {mse}\")"
      ],
      "metadata": {
        "id": "htm-KaNNdoEF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b8db6e6-f350-4ae8-8d94-2e7ea926f12e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected features (RFECV): Index(['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond',\n",
            "       'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtUnfSF',\n",
            "       'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'BsmtFullBath',\n",
            "       'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd',\n",
            "       'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF',\n",
            "       'OpenPorchSF', 'MoSold', 'YrSold', 'MSZoning_C (all)', 'MSZoning_RL',\n",
            "       'MSZoning_RM', 'LotShape_Reg', 'LandContour_Bnk', 'LandContour_Lvl',\n",
            "       'LandSlope_Gtl', 'Neighborhood_Crawfor', 'Neighborhood_Edwards',\n",
            "       'Neighborhood_OldTown', 'Condition1_Norm', 'HouseStyle_1.5Fin',\n",
            "       'RoofStyle_Gable', 'Exterior1st_MetalSd', 'Exterior2nd_Brk Cmn',\n",
            "       'Exterior2nd_VinylSd', 'ExterQual_Ex', 'ExterQual_Gd', 'ExterQual_TA',\n",
            "       'ExterCond_TA', 'Foundation_PConc', 'BsmtQual_Ex', 'BsmtQual_Gd',\n",
            "       'BsmtCond_Fa', 'BsmtCond_TA', 'BsmtExposure_Gd', 'BsmtExposure_No',\n",
            "       'BsmtFinType1_GLQ', 'HeatingQC_Ex', 'HeatingQC_Fa', 'HeatingQC_TA',\n",
            "       'CentralAir_N', 'CentralAir_Y', 'KitchenQual_Gd', 'KitchenQual_TA',\n",
            "       'Functional_Typ', 'FireplaceQu_Gd', 'FireplaceQu_Po', 'FireplaceQu_nan',\n",
            "       'GarageType_Attchd', 'GarageType_Detchd', 'GarageFinish_Unf',\n",
            "       'GarageCond_TA', 'PavedDrive_N', 'SaleCondition_Abnorml',\n",
            "       'SaleCondition_Family', 'SaleCondition_Normal'],\n",
            "      dtype='object')\n",
            "Mean Squared Error (RFECV): 0.020540132410157744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. LASSO with Filter Preprocessing"
      ],
      "metadata": {
        "id": "7S6PhI9hdTSS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EL BLOCK DAH YA HAYAAAAA :"
      ],
      "metadata": {
        "id": "B0vcwXYD4aCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/Machine Learning/scaled_dataset.csv')\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop('SalePrice', axis=1)  # Features (all columns except 'SalePrice')\n",
        "y = data['SalePrice']  # Target variable\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 1: Apply LASSO for feature selection\n",
        "lasso = Lasso(alpha=0.01)  # Adjust alpha for regularization strength\n",
        "selector = SelectFromModel(lasso)  # Use LASSO to select features\n",
        "selector.fit(X_train, y_train)  # Fit LASSO on the training data\n",
        "\n",
        "# Get the selected features\n",
        "selected_features = X_train.columns[selector.get_support()]  # Get the names of the selected features\n",
        "print(\"Selected features (LASSO):\", selected_features)\n",
        "\n",
        "# Step 2: Train and evaluate the model\n",
        "X_train_selected = selector.transform(X_train)  # Transform training data to selected features\n",
        "X_test_selected = selector.transform(X_test)  # Transform testing data to selected features\n",
        "\n",
        "# Train a RandomForestRegressor on the selected features\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "model.fit(X_train_selected, y_train)  # Train the model\n",
        "y_pred = model.predict(X_test_selected)  # Make predictions\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error (LASSO): {mse}\")\n",
        "\n",
        "\n",
        "selected_data = data[selected_features.tolist() + ['SalePrice']]\n",
        "\n",
        "# Save the new DataFrame to a CSV file\n",
        "selected_data.to_csv('/content/drive/MyDrive/Machine Learning/selected_features_dataset_p.csv', index=False)\n",
        "print(\"Selected features and target saved to 'selected_features_dataset.csv'.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgG-4bk_xSWM",
        "outputId": "35a3a9af-62cf-42bc-f7b0-7c9262a5f4fc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected features (LASSO): Index(['MSSubClass', 'LotArea', 'OverallCond', 'YearRemodAdd', 'BsmtQual',\n",
            "       'BsmtExposure', '1stFlrSF', '2ndFlrSF', 'TotRmsAbvGrd', 'Fireplaces',\n",
            "       'FireplaceQu', 'GarageYrBlt', 'GarageCars', 'WoodDeckSF', 'TotalBath',\n",
            "       'TotalPorchSF', 'HouseAge', 'TotalSqFt', 'TotalBsmtFinScore',\n",
            "       'NeighborhoodQuality', 'KitchenQual_ordinal', 'HeatingQC_ordinal',\n",
            "       'MSZoning_RM', 'Condition1_Norm', 'Foundation_PConc',\n",
            "       'GarageFinish_Unf'],\n",
            "      dtype='object')\n",
            "Mean Squared Error (LASSO): 0.08259583352954884\n",
            "Selected features and target saved to 'selected_features_dataset.csv'.\n",
            "Mean Squared Error (Linear Regression): 0.08456310113841625\n",
            "R² Score (Linear Regression): 0.887331604902248\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import Lasso, LinearRegression\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/Machine Learning/scaled_dataset.csv')\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop('SalePrice', axis=1)  # Features (all columns except 'SalePrice')\n",
        "y = data['SalePrice']  # Target variable\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 1: Hyperparameter Tuning for LASSO (Feature Selection)\n",
        "# Define the parameter grid for LASSO\n",
        "lasso_param_grid = {\n",
        "    'alpha': [0.001, 0.01, 0.1, 1, 10]  # Regularization strength\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV for LASSO\n",
        "lasso = Lasso()\n",
        "lasso_grid_search = GridSearchCV(estimator=lasso, param_grid=lasso_param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "lasso_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best LASSO model\n",
        "best_lasso = lasso_grid_search.best_estimator_\n",
        "print(\"Best LASSO parameters:\", lasso_grid_search.best_params_)\n",
        "\n",
        "# Step 2: Apply LASSO for feature selection using the best model\n",
        "selector = SelectFromModel(best_lasso)\n",
        "selector.fit(X_train, y_train)\n",
        "\n",
        "# Get the selected features\n",
        "selected_features = X_train.columns[selector.get_support()]\n",
        "print(\"Selected features (LASSO):\", selected_features)\n",
        "\n",
        "# Step 3: Transform the data to include only the selected features\n",
        "X_train_selected = selector.transform(X_train)\n",
        "X_test_selected = selector.transform(X_test)\n",
        "\n",
        "# Step 4: Hyperparameter Tuning for Linear Regression\n",
        "# Define the parameter grid for Linear Regression\n",
        "linear_param_grid = {\n",
        "    'fit_intercept': [True, False],  # Whether to calculate the intercept\n",
        "    'positive': [True, False]  # Whether to force coefficients to be positive\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV for Linear Regression\n",
        "linear_model = LinearRegression()\n",
        "linear_grid_search = GridSearchCV(estimator=linear_model, param_grid=linear_param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "linear_grid_search.fit(X_train_selected, y_train)\n",
        "\n",
        "# Get the best Linear Regression model\n",
        "best_linear_model = linear_grid_search.best_estimator_\n",
        "print(\"Best Linear Regression parameters:\", linear_grid_search.best_params_)\n",
        "\n",
        "# Step 5: Train the best Linear Regression model on the selected features\n",
        "best_linear_model.fit(X_train_selected, y_train)\n",
        "\n",
        "# Step 6: Make predictions\n",
        "y_pred = best_linear_model.predict(X_test_selected)\n",
        "\n",
        "# Step 7: Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"Mean Squared Error (Linear Regression): {mse}\")\n",
        "print(f\"R² Score (Linear Regression): {r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmfGIKh6zj28",
        "outputId": "7e135ec3-a8a1-4b1f-d27c-ae08e7633d85"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best LASSO parameters: {'alpha': 0.001}\n",
            "Selected features (LASSO): Index(['MSSubClass', 'LotFrontage', 'LotArea', 'OverallCond', 'YearRemodAdd',\n",
            "       'MasVnrArea', 'BsmtQual', 'BsmtExposure', 'BsmtUnfSF', '1stFlrSF',\n",
            "       '2ndFlrSF', 'LowQualFinSF', 'BedroomAbvGr', 'TotRmsAbvGrd',\n",
            "       'Fireplaces', 'FireplaceQu', 'GarageYrBlt', 'GarageCars', 'PavedDrive',\n",
            "       'WoodDeckSF', 'MoSold', 'YrSold', 'TotalBath', 'TotalPorchSF',\n",
            "       'HouseAge', 'IsRemodeled', 'TotalSqFt', 'TotalBsmtFinScore',\n",
            "       'NeighborhoodQuality', 'ExterQual_ordinal', 'KitchenQual_ordinal',\n",
            "       'HeatingQC_ordinal', 'MSZoning_FV', 'MSZoning_RM', 'LotShape_IR2',\n",
            "       'LotShape_IR3', 'LandContour_HLS', 'LandContour_Lvl',\n",
            "       'LotConfig_CulDSac', 'LotConfig_FR2', 'LandSlope_Mod',\n",
            "       'Condition1_Norm', 'Condition1_RRAe', 'Condition1_RRAn',\n",
            "       'Condition2_PosN', 'BldgType_Duplex', 'BldgType_TwnhsE',\n",
            "       'HouseStyle_2Story', 'RoofStyle_Gable', 'Exterior1st_BrkFace',\n",
            "       'Exterior1st_HdBoard', 'Exterior1st_MetalSd', 'Exterior2nd_CmentBd',\n",
            "       'Exterior2nd_Wd Sdng', 'Foundation_PConc', 'Foundation_Slab',\n",
            "       'Heating_GasW', 'Heating_Grav', 'CentralAir_Y', 'Electrical_SBrkr',\n",
            "       'Functional_Maj2', 'Functional_Min1', 'Functional_Mod',\n",
            "       'Functional_Typ', 'GarageType_Attchd', 'GarageFinish_RFn',\n",
            "       'GarageFinish_Unf', 'SaleType_WD', 'SaleCondition_Alloca',\n",
            "       'SaleCondition_Normal', 'SaleCondition_Partial'],\n",
            "      dtype='object')\n",
            "Best Linear Regression parameters: {'fit_intercept': True, 'positive': True}\n",
            "Mean Squared Error (Linear Regression): 0.08163702016008291\n",
            "R² Score (Linear Regression): 0.8912301947519184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/Machine Learning/scaled_dataset.csv')\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop('SalePrice', axis=1)  # Features (all columns except 'SalePrice')\n",
        "y = data['SalePrice']  # Target variable\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 1: Hyperparameter Tuning for RandomForestRegressor (Feature Selection)\n",
        "# Define the parameter grid for RandomForestRegressor\n",
        "rf_param_grid = {\n",
        "    'n_estimators': [100, 200, 300],  # Number of trees\n",
        "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the trees\n",
        "    'min_samples_split': [2, 5, 10]  # Minimum number of samples required to split a node\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV for RandomForestRegressor\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "rf_grid_search = GridSearchCV(estimator=rf, param_grid=rf_param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "rf_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best RandomForestRegressor model\n",
        "best_rf = rf_grid_search.best_estimator_\n",
        "print(\"Best RandomForestRegressor parameters:\", rf_grid_search.best_params_)\n",
        "\n",
        "# Step 2: Apply RandomForestRegressor for feature selection using the best model\n",
        "selector = SelectFromModel(best_rf, threshold='median')  # Use median importance as the threshold\n",
        "selector.fit(X_train, y_train)\n",
        "\n",
        "# Get the selected features\n",
        "selected_features = X_train.columns[selector.get_support()]\n",
        "print(\"Selected features (RandomForestRegressor):\", selected_features)\n",
        "\n",
        "# Step 3: Transform the data to include only the selected features\n",
        "X_train_selected = selector.transform(X_train)\n",
        "X_test_selected = selector.transform(X_test)\n",
        "\n",
        "# Step 4: Hyperparameter Tuning for Linear Regression\n",
        "# Define the parameter grid for Linear Regression\n",
        "linear_param_grid = {\n",
        "    'fit_intercept': [True, False],  # Whether to calculate the intercept\n",
        "    'positive': [True, False]  # Whether to force coefficients to be positive\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV for Linear Regression\n",
        "linear_model = LinearRegression()\n",
        "linear_grid_search = GridSearchCV(estimator=linear_model, param_grid=linear_param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "linear_grid_search.fit(X_train_selected, y_train)\n",
        "\n",
        "# Get the best Linear Regression model\n",
        "best_linear_model =h.best_estimator_\n",
        "print(\"Best Linear Regression parameters:\", linear_grid_search.best_params_)\n",
        "\n",
        "# Step 5: Train the best Linear Regression model on the selected features\n",
        "best_linear_model.fit(X_train_selected, y_train)\n",
        "\n",
        "# Step 6: Make predictions\n",
        "y_pred = best_linear_model.predict(X_test_selected)\n",
        "\n",
        "# Step 7: Evaluat linear_grid_searce the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"Mean Squared Error (Linear Regression): {mse}\")\n",
        "print(f\"R² Score (Linear Regression): {r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kraIoJW91y9z",
        "outputId": "879013ea-a951-4fbb-ce7c-1403c64232be"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RandomForestRegressor parameters: {'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 300}\n",
            "Selected features (RandomForestRegressor): Index(['MSSubClass', 'LotFrontage', 'LotArea', 'OverallCond', 'YearBuilt',\n",
            "       'YearRemodAdd', 'MasVnrArea', 'ExterCond', 'BsmtQual', 'BsmtCond',\n",
            "       'BsmtExposure', 'BsmtUnfSF', '1stFlrSF', '2ndFlrSF', 'BedroomAbvGr',\n",
            "       'TotRmsAbvGrd', 'Fireplaces', 'FireplaceQu', 'GarageYrBlt',\n",
            "       'GarageCars', 'GarageQual', 'GarageCond', 'PavedDrive', 'WoodDeckSF',\n",
            "       'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'TotalBath', 'TotalPorchSF',\n",
            "       'HouseAge', 'IsRemodeled', 'TotalSqFt', 'HasGarage', 'QualitySize',\n",
            "       'TotalBsmtFinScore', 'BsmtFinRatio', 'NeighborhoodQuality',\n",
            "       'ExterQual_ordinal', 'KitchenQual_ordinal', 'HeatingQC_ordinal',\n",
            "       'MSZoning_RL', 'MSZoning_RM', 'LotShape_Reg', 'LandContour_Lvl',\n",
            "       'LotConfig_CulDSac', 'LotConfig_Inside', 'LandSlope_Mod',\n",
            "       'Condition1_Norm', 'HouseStyle_1Story', 'HouseStyle_2Story',\n",
            "       'HouseStyle_SLvl', 'RoofStyle_Gable', 'RoofStyle_Hip',\n",
            "       'RoofMatl_CompShg', 'RoofMatl_Tar&Grv', 'Exterior1st_BrkComm',\n",
            "       'Exterior1st_BrkFace', 'Exterior1st_HdBoard', 'Exterior1st_MetalSd',\n",
            "       'Exterior1st_VinylSd', 'Exterior1st_Wd Sdng', 'Exterior2nd_Brk Cmn',\n",
            "       'Exterior2nd_MetalSd', 'Exterior2nd_Plywood', 'Exterior2nd_Stucco',\n",
            "       'Exterior2nd_VinylSd', 'Exterior2nd_Wd Sdng', 'Foundation_CBlock',\n",
            "       'Foundation_PConc', 'CentralAir_Y', 'Electrical_SBrkr',\n",
            "       'Functional_Maj2', 'Functional_Mod', 'Functional_Typ',\n",
            "       'GarageType_Attchd', 'GarageType_Detchd', 'GarageFinish_RFn',\n",
            "       'GarageFinish_Unf', 'SaleType_New', 'SaleType_WD',\n",
            "       'SaleCondition_Family', 'SaleCondition_Normal',\n",
            "       'SaleCondition_Partial'],\n",
            "      dtype='object')\n",
            "Best Linear Regression parameters: {'fit_intercept': True, 'positive': True}\n",
            "Mean Squared Error (Linear Regression): 0.07603391776689492\n",
            "R² Score (Linear Regression): 0.8986955377408841\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Boruta with Random Forest"
      ],
      "metadata": {
        "id": "6Q1SPc6OdXwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from boruta import BorutaPy\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Initialize the model\n",
        "model = RandomForestRegressor(n_estimators=100, max_depth=5)\n",
        "\n",
        "# Apply Boruta\n",
        "boruta = BorutaPy(model, n_estimators='auto', verbose=2, random_state=42)\n",
        "boruta.fit(X_train.values, y_train.values)\n",
        "\n",
        "# Get the selected features\n",
        "selected_features = X_train.columns[boruta.support_]\n",
        "print(\"Selected features (Boruta):\", selected_features)\n",
        "\n",
        "# Train and evaluate the model\n",
        "X_train_selected = X_train[selected_features]\n",
        "X_test_selected = X_test[selected_features]\n",
        "\n",
        "model.fit(X_train_selected, y_train)\n",
        "y_pred = model.predict(X_test_selected)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error (Boruta): {mse}\")"
      ],
      "metadata": {
        "id": "8CJLPVcKd0yI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}